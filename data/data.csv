channel_name,video_title,video_id,transcript,summary,processed_date
The AI Daily Brief: Artificial Intelligence News,ChatGPT 5.5 Rumors Start to Bubble,Smh50q7UTcY,"Two weeks into the new year and the new model rumor mill is starting to heat up as people are sharing rumors of a forthcoming and new chat GBT model. Welcome back to the AI daily brief. Today we are talking about the latest leaks/ rumors about the next chat GBT model. But I think it's important to put all of this in its proper context. Let's do a quick hit of the last 5 months of OpenAI model releases. Things started pretty inospiciously in August with the release of GPT5. Now, we've gone over lots of times all of the problems with the GPT5 release. One very big problem was the deprecation of 40 alongside it, which had people angry at them for reasons that had nothing to do with the model's performance and everything to do with other changes that were being made at the same time. We've also discussed how if they had simply called their biggest reasoning models like 03 GBT, the perception of the performance jump might have been very different. Basically, in some ways, they were kind of a victim of their own making. Whatever the case, the context it came into was not a great moment for the narrative around AI, and GBD5 did nothing to alleviate that. That's when we were getting these, in retrospect, very silly opeds in publications like The New Yorker, what if AI doesn't get much better than this? Fast forward a couple months, and the pressure was on for Google to deliver. There was a while there where I wasn't even sure that Google was actually going to drop Gemini 3 in November because of the amount of pressure they were under to get it right. But get it right they did. At least in the court of public opinion. When Gemini 3 came out, people were extremely excited about it. They were impressed with Gemini 3 Pro as a model for their intellectual and work tasks. And of course, Nano Banana Pro's ability to make infographics opened up all sorts of totally new possible use cases. It turns out that OpenAI knew they were in for a rough patch. Back in October, it turns out Sam Alman had warned some staff in a memo that he expected some rough vibes around the launch of Google's new models. Rough vibes they got, ultimately leading to Alman and the team at OpenAI declaring a code red. Now what this code red meant in short was a sessation or at least a slowdown of work on a lot of ancillary features and products to double triple quadruple down on core chatbt features including the models underneath powering it. That got us to GBT 5.2 as well as the new chatbt images model which is it should be noted a 1.5 model not a full jump to image gen 2. Now 52 and the new chatbt Images are good models. 52 Pro in particular is very much in my regular rotation and when it comes to a lot of heavy intellectual work, there are many folks who swear by it. Images frankly was better than I expected given how much pressure they had to put that out given Nano Banana Pro. And so even though Gemini and Google had really won a ton of momentum, I do think that the chat GPT releases in December maybe didn't fully stem the bleeding, but for people who weren't interested in the horse race and just wanted high performing models, you felt very lucky with all the options you had over the holiday season. But then of course around all of this was Claude Opus 4.5. The opinion on this model has done nothing but go up and up and up and up. So much so that in a lastminute upset I actually said that I thought it might end up being the most important model release of 2025. And so far at least I think that argument is holding up. Cloud code, Opus 4.5 and AGI are terms that are very frequent co-inhabitants right now of tweets and posts on social networks. Since the beginning of the year, these companies have not slowed down. In a major move to bring cloud code to everybody else, Anthropic released Co-work, tripling down in that way on their source of narrative momentum, while Google and Apple announced the deal that was reported at the end of last year that forthcoming versions of Apple intelligence will be powered in fact by Gemini models. All of this has led to a sense of a lot of momentum around Anthropic and Google and kind of less so around OpenAI. In fact, last night I tweeted that OpenAI seemed to me to be almost conspicuously quiet, which perhaps isn't totally fair given that they announced a major product in CHBT health. But still, it feels to me both like something is percolating and also that perhaps the company decided to try to do a little bit less vague posting in this new 2026 year. Yesterday, the rumor mill kicked back up in a big way. Dan Mack tweeted, ""GBT 53 cenamed garlic coming soon."" According to a source, a very reliable source batting a thousand, expected to be a doozy, likely with stronger pre-training and the IMO gold winning reasoning techniques, the AI leaker account I rule the world responded saying that they had also heard this month and in a separate post shared something that they had told subscribers back in December that the 52 model that we got was a quote rushed early checkpoint and that the full model is going to drop in January. Other speculation is that the model will be multimodal, generating both images and audio. Although no one seems quite clear on the naming conventions, whether it will be GPT55 or even something like GPT53. And of course, while these are all just rumors, although rumors with sourcing, there is also starting to be some evidence that some newness might be percolating and poking through. Andrew Curran tweeted, ""My chat is acting quite differently as of last night. I assumed it was part of a new personality test group. This has happened many times over the last couple of months. OpenAI did say the next big update would make five more personable. It's possible it's about to arrive. Now, maybe I am wrong about the vague tweeting given that VB from OpenAI's developer experience team posted the eyes emoji getting everyone talking as part of this conversation as well. Obviously, anytime we get a new model, it's a very exciting moment. And certainly with the stakes as high as they are, I would love to see a big powerful effort drop that shakes the race up once again. Now, believe it or not, that wasn't the only information in the AI rumor mill. A Chinese consumer electronics blogger has a new leak from their contacts and the supply chain. They wrote, ""Hearing fresh detail on OpenAI to go hardware project from last report, now confirmed it's a special audio product to replace AirPod. Internal code name is Sweet Pee. On manufacturing, Foxcon has been told to prepare for a total of five devices by Q4 2028. All are not known, but a homestyle device and pen are still considered. However, many sources repeated the same thing. Sweet Pea is now front of the line due to the priority of the Johnny IV team. The release has been told to be near September. Volume projection 40 to 50 million in the first year. Only some details currently known. Hardware design is said to be unique, unseen before, and the main devices to be metal and resembling the shape of an eggstone. Inside the eggstone, there are two pills who are removed and rest behind the ear. A custom chip is being developed to allow the device to replace iPhone actions by commanding Siri. And overall, Foxcon leaders are still embarrassed by losing all AirPods programs to Lux. Now they see this as a golden chance to win back the category. We had a show last year about how sneakily AirPods could be the most obvious AI device form factor that not enough people were thinking about in that way. And so it's interesting to see the OpenAI hardware team seemingly exploring some similar space. Although of course something behind the ear is something totally different once again. Now moving away from OpenAI but staying in the new model pool. Another report of a likely model to drop very soon is the next flagship DeepSeek model. The information reports that DeepSseek V4 will be released in midFebruary and will have a heavy focus on coding performance, writes the information. The new model V4 is a successor to the V3 model Deepseek released in December 2024. Initial tests done by DeepSec employees based on the company's internal benchmarks showed that it outperformed existing models such as Anthropics Claude and OpenAI's GPT series in coding. The sources said the report also states that V4 will showcase DeepSeek's advances in handling extremely long context windows, which of course is critical for large coding tasks. Now, obviously, it would be quite the shakeup to have a state-of-the-art open source coding model, but of course, we don't actually know how it'll perform until we see it. Some are convinced, though, that a model cenamed Beluga on LM Arena is our first look at the whale's next release. Deepseek fan tier taxes is skeptical of the sourcing but still believes the hype, posting, I dunk on Breathless Insider leaks about V4, but nobody is more confident than me in what Deepseek is about to achieve. Personally, in my opinion, it'll be the end of the road for Daario style fantasies. Developer Vasio posted, ""Feels like we're about to get another overnight jump that was clearly years in the making."" Deepseek was also in the Western press recently for a different reason with the founder of Deepseek's quantitative hedge fund generating returns of 57% last year, writes Bloomberg's Joe Weisenthal. Man, this dude's had a good couple of years. Now, if those are the fourthcoming model rumors, we also got a small but real update in VO31 ingredients to video. The feature allows users to upload reference images for characters, props, and background to guide the video generation. Google said the upgrade makes videos more expressive and creative, even with simple prompts. They also promised better visual consistency across multiple scenes to ensure clips can be easily stitched together to tell a coherent story. Vio can also now use ingredients to video when generating vertical videos for mobile which wasn't previously possible. And in a last bit of lab news, which isn't a model right now, but could be an interesting product in the future, Anthropic has announced the expansion of their labs team into a full-blown internal incubator. Anthropic Labs was started in mid 2024 with just two members and helped develop Claude Code, MCP, and more recently Co-work. Labs will now become a more substantial part of the company with Anthropic aiming to double the lab's headcount within the next 6 months. The expanded team will be co-led by chief product officer Mike Kreger and product engineering lead Ben man. The team will report to anthropic president Daniela Amade. Now, if you want to hear more about how Mike thinks about building AI products, I did an interview with him as part of our end of year episodes which you can find on YouTube or on this podcast feed. Ultimately, it sounds like a big part of the move is about restructuring the team so that Anthropic's product philosophy can match the rapid pace of the industry. Wrote Daniela. The speed of advancement in AI demands a different approach in how we build, how we organize, and where we focus. Labs gives us room to break the mold and explore. Look, if it leads to more products like Cloud Code, I think most folks in the industry will say count us in. For now, that's the latest on what's cooking around the AI rumor mill. Hopefully, we get some real models in the next couple of weeks to explore. For now, though, appreciate you listening or watching. as always and until next time.","**AI Model Rumors Heat Up: ChatGPT 5.5, DeepSeek V4, and More**

The **AI** landscape is abuzz with rumors of new model releases, and we're here to break down the latest developments. Two weeks into the new year, the rumor mill is gaining momentum, with whispers of a forthcoming **ChatGPT** model, potentially dubbed **GBT 5.5** or **GPT 5.5**. This comes on the heels of **OpenAI's** previous releases, including **GPT 5** and **GBT 5.2**, which aimed to address the performance concerns surrounding the initial **GPT 5** launch.

**Context is Key**

To understand the significance of these rumors, it's essential to consider the context of the past five months. **OpenAI** faced criticism for the **GPT 5** release, which was marred by issues with the deprecation of **GPT 4**. Meanwhile, **Google** delivered with the release of **Gemini 3**, which impressed users with its capabilities. **Anthropic** also made waves with the launch of **Claude Opus 4.5**, a model that has garnered widespread acclaim and is being hailed as a potential game-changer.

**Rumors and Speculation**

The rumors surrounding **ChatGPT 5.5** suggest that it may feature **stronger pre-training** and **improved reasoning techniques**. Some speculate that the model could be **multimodal**, generating both images and audio. While these are just rumors, there is evidence to suggest that **OpenAI** is working on something new, with users reporting changes in their **Chat** interactions and **OpenAI** developers hinting at an upcoming update.

**Other Model Releases**

It's not just **OpenAI** that's making waves in the **AI** community. **DeepSeek** is rumored to be releasing **V4**, a flagship model that promises to deliver exceptional **coding performance**. **DeepSeek V4** is expected to outperform existing models, including **Anthropic's Claude** and **OpenAI's GPT series**. Additionally, **Google** has announced an upgrade to its **VO31** ingredients, allowing users to upload reference images for character, prop, and background generation.

**Anthropic Labs Expansion**

In other news, **Anthropic** has announced the expansion of its **Labs** team into a full-blown internal incubator. This move aims to accelerate the development of innovative **AI** products, such as **Cloud Code** and **Co-work**. The expanded team will focus on building products that match the rapid pace of the **AI** industry.

**Key Takeaways**

* **ChatGPT 5.5** rumors suggest a forthcoming model with improved performance and potentially multimodal capabilities
* **DeepSeek V4** promises to deliver exceptional coding performance and may outperform existing models
* **Anthropic** expands its **Labs** team to accelerate **AI** product development
* **Google** upgrades its **VO31** ingredients for improved video generation
* The **AI** landscape is rapidly evolving, with new models and products being released regularly

Stay tuned for more updates on these developments, and get ready to explore the latest **AI** models and products in the coming weeks. The **AI** rumor mill is heating up, and we can't wait to see what's in store for the future of artificial intelligence. 

**Social Media Post Ideas:**

* ""The #AI rumor mill is heating up! What do you think about the latest rumors surrounding #ChatGPT 5.5? Share your thoughts! #AI #MachineLearning""
* ""Get ready for a shake-up in the #AI landscape! #DeepSeek V4 is rumored to deliver exceptional coding performance. Stay tuned for more updates! #AI #Coding""
* ""What's next for #Anthropic? The company is expanding its #Labs team to accelerate #AI product development. Exciting times ahead! #AI #Innovation""",2026-01-15T10:33:27.276995
NextWork,FinOps project for your resume (day 6),zYvfzaGe8ZQ,"By the end of this video, you will have a live e-commerce website deployed on the same infrastructure that companies like Tik Tok, Walmart, Nike, Stripe, and more use all across the world. This is project number one in our Phops XAI series where we will show you the skills that modern developers are using to build and manage cloud costs at scale. Companies need people who can build, deploy, and optimize without burning through money. And this is exactly what you're going to learn today. We're going to be using platforms like Vzero, Versel, GitHub, and Cursor. And in the upcoming projects, we're going to integrate in Stripe, which is a skill set that any developer would need. And we're also going to look at analytics so that you can optimize your conversion funnel. You don't need any experience. This project is free. Make sure that you are going through and adding in your answers to these questions plus screenshots cuz at the end you will get documentation that looks like this where you can change the theme and you can also share this to places like LinkedIn or the community or download it as a PDF, PNG, markdown, any of these social platforms. It just means that the work that you're doing actually gets showcased to recruiters and it's going to help you stand out and land a","**Unlock the Power of FinOps: Boost Your Resume with a Live E-commerce Website**

Are you ready to take your developer skills to the next level and stand out to recruiters? In this exciting project, you'll learn how to build, deploy, and optimize a live e-commerce website on the same **cloud infrastructure** used by top companies like TikTok, Walmart, Nike, Stripe, and more. This is the first project in the **Phops XAI series**, designed to equip you with the skills modern developers need to manage **cloud costs** at scale.

**Key Takeaways:**

* Deploy a live e-commerce website on a **scalable infrastructure**
* Learn to use platforms like **Vzero**, **Versel**, **GitHub**, and **Cursor**
* Integrate **Stripe** and **analytics** to optimize your **conversion funnel**
* Create a **professional documentation** of your project, complete with screenshots and answers to key questions
* Share your work on **social platforms** like LinkedIn, or download it as a **PDF**, **PNG**, or **Markdown** file

**Why is this project important?**

Companies need developers who can build, deploy, and optimize without breaking the bank. By completing this project, you'll demonstrate your ability to manage **cloud costs** effectively, making you a more attractive candidate to recruiters. Plus, with no prior experience required, this project is perfect for anyone looking to **upskill** or **reskill** in the world of **FinOps**.

**What's next?**

In upcoming projects, you'll dive deeper into **FinOps** and learn how to integrate **Stripe** and **analytics** to optimize your website's performance. You'll also have the opportunity to showcase your work on **social media** and share it with the community, increasing your visibility and chances of landing a job.

Don't miss out on this opportunity to **level up** your developer skills and create a **showcase-worthy** project that will impress recruiters. Join the **Phops XAI series** today and start building your path to a successful career in **FinOps**! 

Example social media posts:

* ""Take your developer skills to the next level with our #FinOps project! Build, deploy, and optimize a live e-commerce website on the same infrastructure used by top companies like TikTok and Walmart. #cloudinfrastructure #PhopsXAI""
* ""Want to stand out to recruiters? Create a professional documentation of your #FinOps project and share it on #LinkedIn or other social platforms. #FinOps #careeradvice""",2026-01-15T10:36:43.970662
NextWork,FinOps x AI Stripe Project (step-by-step),BQoSk78uRmY,"Companies like Shopify, OpenAI, Etsy process billions of dollars through Stripe. That is the payment infrastructure that handles over 300 compliance requirements so that you don't have to. And the thing is that so many devs get this wrong. They mishandle keys. They skip web hooking configuration. And in today's project, you are going to learn how to add in Stripe to an e-commerce website that is live deployed on Versel. And you're going to learn all about how to set it up securely. You'll also learn about serverside pricing, web hooks, and signature verification. This is a project you're going to want to add to your resume and it's going to impress recruiters. Let's just get straight into the video. If you want this entire project, head to learn.network.org. This is called the secure payments with Stripe project. And as you're going through the project, make sure to fill in these questions and screenshots because you'll get documentation that you can then add to your own LinkedIn, GitHub, or any other platform. This is the stuff that is going to help you stand out to recruiters. You need to be able to show that you can document your work and actually prove your skills. This is part two of the Phops AI series. So, I'm assuming you've already deployed your Next.js e-commerce app. If you haven't, I'd recommend following this project guide or the YouTube video that I'll put on screen now to actually go ahead and complete this project. It's vital that you get this done. It's going to teach you the basics that you need for the project that we're about to do. All right, but let's get into today's project. The first thing we need to do is actually create a Stripe account. So, I'm going to go to sign up and I'm going to create an account. I'm just going to sign up with Google to make it easy. Create account. Stripe might ask you for a business name here. You can just skip this for now. It's going to ask you for a lot of stuff. Skip this all. Don't skip this one, though. Let's click go to sandbox. And this is going to put me in a test mode where I can safely experiment without processing real money for this wizard on the side. Just go ahead and close that. And now we need to go ahead and find our API keys. So I'll go to settings right here, developers, and then I want to click manage API keys. And here you can see two keys. There's a pushable key that starts with PK test, and there's a secret key that starts with SK test. These two keys are very different. I'd kind of think about it like this. Your publishable key is like giving someone permission to submit a payment form. Whereas a secret key is like giving someone your entire bank account. So let's not do that. Now I need to store that secret key in our environment variables. And the reason we do this is because let's say we're in this scenario here where we've hardcoded our secrets. We've written code like this and it gets pushed to GitHub. Even if our repo is private, this does not mean we're safe. Let's say another team member forks our repo and then it becomes public or former employees they might still have access to our commit history. GitHub has been breached before and once a secret is in version control. It is there forever. You can't delete it later. So that's why we use environment variables. This is where you write good code like this and this secret lives in what we call aenv file. And this file never gets committed to GitHub. It is in our git ignore files. So when our code runs it reads the secret from the env file. the secret stays safe on our machine and on Versell service. It never touches GitHub. So, let's see how we actually set this up. So, I'm going to go to my Versel dashboard here and I'm going to navigate to my e-commerce web app project. Once I'm in here, I'm going to go to settings. I'm going to click on environment variables. I'm going to scroll down to key here. I'm going to call this stripe secret key. I'm going to go back to Stripe, copy my secret key, paste this as a value in VELL, and I want to keep all environments selected. This means that the key will be available in production, preview, and development deployments. And I can go ahead and hit save. Vel is just going to show a popup confirming that everything is saved. The secret is now stored in Versel servers, but it's not in my code. So, I need to do the same thing locally so that my development environment can access Stripe. So, I'm going to open up cursor just here, and I'm going to open my project. and just make this full screen. Close these up. And on the right hand side here, I'm going to make a new file. And I'm going to call this enenv.local. So I'm just going to type in stripe secret_key again space equals and then paste in my key and hit save. So now my local.env local file has the same secret and my actual code doesn't contain the secret. So when the code deploys, Versel injects the secret at runtime. And when I run this locally, Node is going to read this from my env local file. You'll know this is working when your app can make Stripe API calls without hard coding your key anywhere in your source code. One thing I did by mistake here is my secret key should actually have no spaces after the secret key and after the equal sign. Make sure you save that. If your secret key does ever get exposed, it happens. Rotate it immediately. So, just follow this project guide here and it's going to show you how to rotate your key away. But hopefully you've listened to the steps so far and you haven't done that. So the next thing we need to do here is actually build our payment flow. So I'm still in cursor right here and I'm going to open up a new chat window. You can either press control L or command L if you're on a Mac. Otherwise just hit this little toggle in the right hand corner and we're going to say run this e-commerce web app by installing the packages first and then running the app. So I can just go ahead and hit enter and it's going to go ahead and do its thing. cursor is going to go ahead and install all the dependencies that I need. So everything my app needs to run this locally. That's everything my app needs to run. So all the libraries, packages, and frameworks. And it's all done now. So it's started up my dev server. If you don't like running this in cursor, you can also just copy localhost to a browser and just hit enter. And you can also see this on a browser. So in this step here, I'm going to navigate around like I'm buying something. So I can just click through here. And the thing is now I need to create an API route. So what is an API route? Now, an API route is essentially a secure doorway or postal address within our web application. So, it's a specific endpoint that allows different parts of our application or even other services to send and receive information securely. When this user in the front end clicks buy now in their shopping cart, this sends an HTTP post request to the checkout API route. This API route acts as a secure doorway. It then communicates to our backend server to verify the product price server side. Don't worry about server side. We're going to talk about this in a little bit, but this is crucial to fraud prevention. Our back-end server then interacts with Stripe to create a checkout session. Stripe returns a unique URL to the backend server. And then finally, the users browser is redirected to the Stripe checkout page using that URL to complete the payment. So instead, this API route ensures that sensitive payment information and price validation is handled securely on the server as opposed to the users browser. So let's actually do this. We're going to go to the project guide right here, copy this in, and we're going to paste this into cursor and hit enter. So, cursor is going to install the Stripe package and generate the API route. While it's doing that, let's explain what it actually just did. Actually, before we do that, make sure you like and subscribe because it is 10:59 p.m. and I'm recording this video for you because I know this is a cool project, but please subscribe. It means a lot. All right, so this prompt that we just put in, number one, is using Stripe to create checkout sessions. And that checkout session is just Stripe's payment flow. and it contains the product info, the price, and where to redirect the payment. Number 2, three, and four explain why we need server side versus client side pricing. And this is why we have server side pricing instead of client side pricing. Let's look at client side first. So, I'm going to go to the Apple page here. Oh man, I really want a new MacBook. I don't want to pay $1,999. Like, that's kind of crazy. I'm going to select this element right here. And then I'm just going to change this to a dollar. You know what? I'm feeling generous. $1.99. Cool. The price is now $1.99. That's all I got to pay. Do you see what I just did? I just modified the price in my browser. Now, if Apple trusted this client side price, it would let me buy a MacBook for $1.99. And I would buy every single MacBook there is and sell them to you guys for $2.50 cuz I'm that generous. But do you see the problem? We're trusting the client side, which is something that we can't do. That's why server side exists. This is our backend API route that we just looked at. It is secure and it is trusted. So someone might still change the price on the client side, but the server is going to look at that MacBook Pro product one and it's going to search its own dictionary and see the real price is actually $599. The server is going to ignore the front-end price completely and process the payment for $599. In this case, I think the MacBook was like what was it? $1,999, but you get the point. The front end can request the product, but it can't control what the product actually costs. So then if we go back to the rest of the commands, number five is going to create a checkout URL to Stripe's hosted payment page, it's going to look something like that. Number six is going to use our secret key from our environment variables, which we just looked at. And then number seven is going to redirect to either a successful payment or a cancelled payment. So Stripe should be all done here. And now we need to connect this button to the API. So I'm going to actually use Curs's element select tool here. And I'm going to click this payment button. And this is going to add this context chat. And I'm going to ask cursor to implement the Stripe payment API here and hit enter. All right, awesome. It looks like it worked. I'm going to deselect this. Close this up. So now I'm just going to go through the workflow just here. Click buy now. Going to type in my email address. Pay. Oh, and it's working. You can see it's a different URL here. I'm on the Stripe hosted checkout page. And this is Stripe's checkout. So car details get entered on Stripe servers, not yours. You never touch card data, which drastically reduces your PCI compliance requirements. Basically, just a bunch of data rules that you have to follow. And I can enter in some testing here. 242. Add in any dates in the future. 29 any CVC. And I'm going to hit pay. We have a 404 page here. So, something did not go right. So, let's go ahead and say this should take me to a success page as opposed to a 404 page. Please fix this. Going to go ahead hit enter and see what happens here. That's looking a bit better, but I don't need session ID. Take out session ID from there. Cool. That's looking a lot better. But the problem here is the success page isn't really proof of any payment, right? Anyone can navigate to this link/success without actually paying. We need cryptographic proof that the payment has succeeded. And this is where the next step comes in and it is web hooks. This is what secure web hooks can be used for. So, right now in app when someone completes a payment, Stripe redirects them to our success page. But that redirect isn't proof that they've actually paid. Like anyone can type in our website/success and they're going to get that success page. So, we need Stripe to tell our server, hey, that payment actually succeeded. And that is what web hooks are for. So, when a payment completes, Stripe is going to send data to a URL that we specify. And this is done through a post request. And it's essentially how systems send data over the internet. This is going to include things like the amount, status, and the customer details. Now, our server is going to receive this notification and we can save it to our database. We can send a confirmation email and we can fulfill the product request. But there is a problem. Any evil attacker like this guy can send a post request to our server. If our web hook endpoints accept any post request claiming to be from Stripe, attackers are going to send fake payment confirmations. They don't need to hack Stripe. They just need to know our web hook URL and send their own post request with fake data saying the payment succeeded for $599. So let's see how easy that is to do. So I'm going to go back to the project guide here and copy this in. And essentially we're saying create a strike web hook endpoint at app API web hooks stripe route ts that one accepts post request with stripe event data. Two handles the checkout session complete event. Three logs the event details to the console. And four returns a 200 status on success. So I can paste this into cursor and let it do its thing. And cursor is going to generate the web hook endpoint. And the thing is the endpoint just accepts any post request. It doesn't verify that the request actually came from Stripe. So again, if I go back to the project guide here and just copy this in and I paste this command into the terminal pretending to be an attacker sending a fake web hook. I'm going to paste it in my terminal. Hit enter. And you can see that it was in fact received. And if I look at my server terminal, it says that the session is completed and the payment status is paid. You can see here that it also says that it's skipping signature verification and this is exactly what we need. So I can go to the project guide here. I'm going to copy in this command. I'm going to create a new window and I'm going to paste this in. And what cursor is doing is it's updating the web hook endpoint with signature verification. So here is what a signature verification does. So Stripe is going to sign every web hook with a secret key that only you and Stripe know. And this signature is sent in the stripe signature header to verify the signature matches the web hook body. So if the signatures match, it means the web hook is authentic. And it also means our server is going to process the event. So it'll save the data, send an email, that kind of stuff. If the signatures don't match, it indicates that there's a potentially malicious or altered web hook. And our server is going to reject this and it's going to log the event as an alert. The thing is only Stripe can generate valid signatures because only Stripe has that signing secret. So now I want to go and get this signing secret from Stripe. So this time I'm going to go to the bottom left hand corner of my screen here and click on developers and I'm going to click web hooks. From here I'm going to click add destination. And I want to search up in these events checkout session completed. So I'm going to take that and I'm also searching up payment intent. Payment failed and I'm going to click continue. Keep it on web hook endpoint. And here I'm going to call the destination name. Now for the destination name I'm going to name it payment web hook and the endpoint URL we actually need to go back to versel here. I'm going to go to deployments, click on the latest branch and copy this link address. I'll go back into the endpoint URL here. And we also want to add in an API/ web hooks/stripe. We can then go ahead and click create destination. And what we want to do is copy this to clipboard. This signing secret right here. Now we need to add this over cell. So I'm going to click back just here. I'm going to go to settings environment variables. Uh my key here I'm going to call stripe web hook secret. Paste in my whsec value. Click save. So you can see it down here. And we also need to do this in our code as we did before. So let's go to our env file here. Stripe web hook secret equals and then paste in our value. Hit save. And I'm going to tell cursor to restart my dev server here and redeploy my app. So it picks up the environment variable change. Well, cursor actually did what I was about to do, which was add in what I just did. But essentially all you need to do is go get add dot and then we'd go get commit-m add stripe web hook with signature verification and then we want to get push but for me it's all up to date. So versel is going to automatically deploy this. Let's verify that that security fix is actually working as well. So I'm going to run the same uh fake web hook command again. Paste that in. Hit enter. Guys, I'm not going to lie. It's 12:11 a.m. So, I spelled Stripe wrong and that's why it's not working. So, now I need to restart my dev server. Hit enter. Guys, I'm tired. I'm pretty tired, but this is a fun project. I can't lie. So, let's test that command out again. Hit enter. And you got invalid signature. Okay, it worked. Let's go. The signature verification would have detected that this request didn't come from Stripe and it refused to process it. So, everything is beautiful. Make sure you push all your changes. And I'm not talking about these environment variables. Obviously, those aren't getting pushed to GitHub. That's literally the whole point of them. But all the other changes that we made to our app, they should be pushed to GitHub and deployed. So now, let's test with a real payment. I need to use my live versel website for this. I'm going to click into here. And that is because my Stripe web hook is configured to hit my production URL, remember? So, I'm going to go through my deployed site. I'm going to go explore products by now. Let's check this out. maximus@nextwork.org pay. We're going to hit that Stripe page exactly like this. I'm going to put in some fake details right here. Cool. I'm going to complete the payment. And you can see that things were successful. But now I'll go into the Stripe dashboard here. I'm going to refresh. If I go to event deliveries, you can see that the checkout session was completed. We got a status 200. So, Stripe sent the payment confirmation to my server and then my server verified the signature and responded. So, the web hook is now working. Let's go. I have cryptographic proof that the payment succeeded. I am actually so happy. This is such an awesome project, guys. Make sure you're adding in screenshots as you continue. So, you actually get documentation that you can then share to LinkedIn, GitHub, or any other platform. Documenting your work is really the thing that's going to help you stand out to recruiters because it proves that you're actually doing something. Otherwise, you have nothing to show. If you enjoyed this video, make sure to like, subscribe, all of that. And I will catch you in the next one. This is project two, remember? So, there's another one coming out tomorrow. I'm going to get some sleep.","**FinOps x AI Stripe Project: A Step-by-Step Guide to Secure Payment Integration**

In this comprehensive project, you'll learn how to integrate **Stripe** payment gateway into an e-commerce website deployed on **Versel**, while ensuring **security** and **compliance** with over 300 requirements. The project focuses on **FinOps** (Financial Operations) and **AI** (Artificial Intelligence) to provide a seamless payment experience.

**Key Takeaways:**

1. **Setting up Stripe**: Create a Stripe account, obtain **API keys** (publishable and secret), and store the secret key securely using **environment variables**.
2. **Server-side Pricing**: Implement **server-side pricing** to prevent **fraud** and ensure **security**. This involves creating an **API route** to handle payment requests and verify product prices on the server-side.
3. **Web Hooks**: Configure **web hooks** to receive payment confirmations from Stripe, ensuring that only legitimate payments are processed.
4. **Signature Verification**: Implement **signature verification** to authenticate web hook requests and prevent malicious attacks.

**Step-by-Step Process:**

1. Create a Stripe account and obtain API keys.
2. Store the secret key securely using environment variables.
3. Set up server-side pricing by creating an API route.
4. Configure web hooks to receive payment confirmations.
5. Implement signature verification to authenticate web hook requests.
6. Test the payment flow with a real payment.

**Important Concepts:**

* **API Routes**: Secure doorways for sending and receiving information between services.
* **Server-side Pricing**: Verifying product prices on the server-side to prevent fraud.
* **Web Hooks**: Receiving payment confirmations from Stripe.
* **Signature Verification**: Authenticating web hook requests to prevent malicious attacks.

**Best Practices:**

* Store sensitive information, such as API keys, securely using environment variables.
* Implement server-side pricing to prevent fraud.
* Use web hooks to receive payment confirmations.
* Verify the authenticity of web hook requests using signature verification.

**Conclusion:**

By following this step-by-step guide, you'll be able to integrate Stripe payment gateway into your e-commerce website while ensuring security and compliance. Remember to document your work and share your progress on platforms like LinkedIn and GitHub to showcase your skills to recruiters.",2026-01-15T10:37:10.847084
NextWork,A mistake people make with GitHub,OLrjVJeq3MI,"Now, here's what we're actually doing. We're setting up a secure way to connect our computer to GitHub so we can push and pull code. Now, GitHub used to let you use a username and password over HTTPS, but that was deprecated in August 2021. Now, you use tokenbased authentication, and SSH keys are the standard method that developers use all around the world. SSH stands for secure shell, which I know is a bit weird. Why didn't we add another H on there? And an SSH key is what we call a cryptographic key pair. So you actually get two keys, a public key and a private key. The public key that goes on GitHub and the private key that stays on your computer. Then when you connect, GitHub validates that those keys actually match. So it's very secure. And there's actually three main reasons why we use SSH over something like HTTPS. The first of which is pretty simple. You don't have to type your password in every single time you push or pull, which is a lifesaver. Second, it's more secure than password authentication. And third, it is just simply industry standard. Now, every company that you join would likely need you to know this. Before you go, make sure you check out these hands-on projects. It's the best way to learn. You can put into practice all of these skills through step-by-step guides. Plus, you also get documentation that you can share to recruiters on different platforms like LinkedIn, GitHub, or any other social media. The best way to learn is do things hands-on. Break things.","**Unlock the Power of Secure Coding with GitHub**: Are you making a crucial mistake with your GitHub setup? It's time to learn about the importance of **token-based authentication** and **SSH keys** in ensuring a secure connection between your computer and GitHub.

The days of using a **username and password** over **HTTPS** are behind us, as this method was **deprecated in August 2021**. Now, developers rely on **SSH keys**, a **cryptographic key pair** consisting of a **public key** and a **private key**. The **public key** is stored on GitHub, while the **private key** remains on your computer, allowing for a secure connection.

But why do developers prefer **SSH over HTTPS**? There are three key reasons:

1. **Convenience**: With **SSH keys**, you don't need to enter your password every time you **push or pull code**, saving you time and effort.
2. **Security**: **SSH keys** offer a more secure way to authenticate, reducing the risk of password-related breaches.
3. **Industry Standard**: **SSH keys** are the **industry standard**, and knowing how to use them is a valuable skill that can open doors to new opportunities.

To take your coding skills to the next level, it's essential to practice **hands-on learning**. Engage with step-by-step guides, work on projects, and showcase your skills to recruiters on platforms like **LinkedIn** and **GitHub**. Remember, the best way to learn is by **doing**, so don't be afraid to **break things** and try again.

Key takeaways:

* **Token-based authentication** is the new standard for GitHub connections
* **SSH keys** are a **cryptographic key pair** consisting of a **public key** and a **private key**
* **SSH keys** offer **convenience**, **security**, and are the **industry standard**
* **Hands-on learning** is the best way to develop your coding skills

Share your thoughts on the importance of **SSH keys** and **token-based authentication** in the comments below! #GitHub #SSHkeys #TokenBasedAuthentication #Coding #Security #IndustryStandard #HandsOnLearning",2026-01-15T10:38:54.856276
Fireship,The unhinged world of tech in 2026...,EKOU3JWDNLI,"The year is 2026. Your $3,500 smart fridge has a GPU and displays advertisements. Your boss is an AI. Your girlfriend is a robot. And every startup pitch sounds like Uber, but quantum. Welcome to the future. It's somehow both overengineered and still in beta. But it's time for the annual tradition where I wake up the vat of precogs in my garage and tell you exactly what's going to happen this year. Last year, I told you AI agents would be the biggest thing in tech. And if you would have just listened to me, you'd be a billionaire right now. But you didn't listen. In fact, I didn't even listen to myself, and now it's too late to frontr run this trend. But all is not lost. There are some even bigger trends emerging in Silicon Valley right now. And as long as the record-breaking stock market doesn't crash, there's an endless supply of money being thrown around that can still make us all billionaires. In today's video, we'll look at 10 trends in technology, covering everything from AI slop to nuclearpowered quantum sex robots to new JavaScript framework features that will finally make the world a better place. It is January 14th, 2026, and you're watching the Code Report. Not everybody is cut out to become a billionaire AI grifter, but the next best thing is landing a stable, high-paying job doing some honest software engineering work. But will those jobs even exist in 2026? Unfortunately, the good old days of 2023 don't seem like they're coming back after the 2023 tech pullback and the rise of AI coding tools that followed. The amount of job openings on Indeed for software engineers have not regained their original glory. But this ominous looking chart doesn't tell the full story. On a more positive note, the Bureau of Labor Statistics is still forecasting 15% software development job growth through 2034. In addition, back in September, a major change to the H1B program might be good news or bad news depending on who you are. If you weren't lucky enough to be born in the United States, you'll now have a $100,000 fee to apply for an H-1B visa. And that makes it far more difficult for US-based tech companies to hire cheap labor from overseas. The good news though is that despite what the optimist will tell you, AI coding tools are still nowhere close to replacing human engineers. And I have zero fears that that's going to change in 2026. In fact, all the vibe coded slop out there is creating a whole new class of jobs called code janitors who need to clean up all the garbage code created by these AI tools. But where is AI itself headed? Everybody knows we're in a bubble with valuations that make zero sense. But the question is, are we at the peak of this bubble, or are we still another decade away from the peak? I'd argue that we still have at least a few more years to keep this hype cycle alive. It's pretty obvious now that LLMs as a technology have plateaued and are not actually intelligent. When GPT5 came out a few months ago, it was a huge disappointment and we're not seeing the exponential leaps in intelligence that a truly intelligent self-improving AI system should be able to make. But don't get me wrong, though. The current AI technology is legit amazing. Remember, we're only a few years into this trend. programmers were the early adopters of the prompt casino, but there are companies out there working day and night to replace stupid, smelly, squishy humans. And if you're someone who does spreadsheets for a living, is a mid-level manager, or even a graphic designer, you might no longer be necessary in the future. AI is definitely stacking up victims in the job market, and even activities that were once respected, like being a Stack Overflow poster, are now completely dead, just as I predicted a few years ago. But another sign the bubble's not over yet is the fact that most AI companies are still private. Eventually, a time will come when you see a wave of IPOs in the stock market to hand these bags from VCs over to the public. And when that wave of IPOs arrives, you'll know the charade is coming to an end. And there's a good chance that wave comes in 2026 as SpaceX, OpenAI, and Anthropic are all looking to go public with some of the biggest IPOs in the history of the world. But before that happens, one of the biggest drivers to keep the AI hype going in 2026 will be robots, humanoid robots. Just a few weeks ago, 1X started taking orders for their Neo robot, which can do your laundry, wash your dishes, and just be a friendly, helpful slave that will never rebel. In addition, Figure Robots and Tesla Optimus are being pushed as replacements for manual labor in factories. As of today, the tech is still pretty bad and requires a lot of tea operation, but companies like Google and Nvidia are providing the base technology that allows any founder to Frankenstein together some clanker and raise a bunch of money. 2026 is the year we'll finally see these things roll off of assembly lines. But what if you could turn yourself into a robot or cyborg? Well, wearable AI tech is another big trend to watch for. We've already had massive flops like the Rabbit and Humane Pin, but OpenAI is still in collaboration with Johnny IV to make some wearable that will actually be good this time, or so they say. In addition, you've got old companies like Nike building things like batterypowered shoes that will finally allow the white man to jump. And I can't wait for the NBA to approve this and see dudes dunking from half court. But until that day comes, I'd rather just get my entertainment from virtual worlds in my VR headset. The Apple Vision Pro was supposed to finally make virtual reality mainstream, but as I correctly predicted, it was a massive flop. I got a lot of hate from Apple fanboys for making that prediction, but it's not over for the Vision Pro. There are rumors of a lowerc cost version in the works that could turn this flop around. Meanwhile, Meta is making huge investments in augmented reality. But ultimately, I think the VR AR space will mostly remain an unprofitable niche area, even though the tech itself is extremely impressive. But the lion share of the profits are going to continue flowing into chip designers like Nvidia and ARM and chip fabricators like Taiwan Semiconductor. AI mania has created an insatiable demand for linear algebra. And the barriers to entry in this industry are so high that these companies will continue to slurp up most of the profit. The only company that really screwed things up is Intel, which is both a chip designer and a fab. And in 2025, it looked like it was on the verge of going out of business. But luckily, Trump stepped in and had the US government buy a 10% stake in Intel, thus preventing the free market from working like a free market. And Intel is poised to continue its turnaround in 2026. It's just too big to fail. But cloud providers like Azure are having a hard time even finding enough electricity to plug in their Nvidia GPUs. As demand for AI scales up, it could lead to a resurgence in nuclear power even as many countries in the west start to dismantle their reactors. China, on the other hand, is building all kinds of new reactors. But there are companies like Ollo, which are attempting to get regulatory approval for these small modular reactors, which could potentially give every data center its own self-contained power source. Instead of acres of these ugly intermittent solar farms or wind farms, the future might have these tiny little reactors in every neighborhood. But what could possibly go wrong? And we're already seeing this play out with Zuckerberg announcing a big deal with Olo to put a reactor in Ohio. But maybe this trend will never play out because computers get colder and faster, like billions of times faster, running at absolute zero temperatures. In 2025, we saw some major advancements in quantum computing, most notably with Google's Willow chip. Then just a few months ago, Google announced its quantum echoes algorithm that measures disturbances at the subatomic scale. For the first time in history, a quantum computer has actually run a verifiable algorithm that surpasses the ability of supercomputers. The quantum computers have been in development for decades now. But what's exciting is that we're finally starting to see the possibility of practical applications in the real world. When quantum computing hits version 1.0, it'll make the AI bubble look like child's play, and American and Chinese researchers are racing to get there first. But European tech leaders are also making big strides in technology, especially when it comes to water bottle caps. and with the highly unpopular digital IDs along with central bankbacked digital currencies. Despite nobody actually wanting these things, bureaucrats keep pushing them forward like it's a speedrun to the Black Mirror season finale. In the near future, every government endorsed smartphone will become a portal to your bank account, your location, your social media posts, your adult website visits, and so on. The UK has been adamant that digital IDs are coming. While the European Central Bank recently announced that the Eurozone's digital euro pilot is moving into its next phase with the pilot program expected as soon as mid 2027 and full issuance of a digital currency by 2029. They can take our lives and they can take our freedom but they can't take our JavaScript. On the back end, Node.js keeps getting better and better and now supports TypeScript files with TypeScripping. Meanwhile, Dino keeps getting better and now has its own built-in module bundler. But all the kids these days are talking about bunjs, a runtime that keeps getting faster, but also has built-in support for Postgress and Reddus, making it a very tempting choice for any new JavaScript project. On the front end, ReactJS still dominates despite the fact it sucks. But in the future, it will suck less now that the compiler is officially stable. I'd still take spelt or view or it even Angular over React, but there's still new JavaScripts hitting the scene like Ripple, which should be on your radar in 2026. But if you're looking to level up your skills this year, you need to check out Brilliant, the sponsor of today's video. I'd highly recommend their how AI works course, which teaches you how to build a functioning language model from scratch. You'll get to experiment with things like feature vectors to edit facial expressions and images along with other hands-on lessons that are personalized to your skill level, so you can master challenging topics over time. To check out brilliant.org/fireship org/fireship to learn for free for a full 30 days or scan the QR code on screen to get 20% off an annual premium subscription with unlimited daily access. This has been the code report. Thanks for watching and I will see you in the next one.","**Welcome to 2026: The Year of Unhinged Tech**

As we dive into the new year, the tech world is more fascinating than ever. From **smart fridges** with GPUs to **robot girlfriends**, the possibilities seem endless. But beneath the surface, there are significant trends shaping the industry. In this summary, we'll explore the top **tech trends** of 2026, including **AI**, **quantum computing**, **wearable AI**, and **JavaScript** advancements.

**The AI Bubble: Is it About to Burst?**

The **AI hype** is still alive and kicking, with valuations that make little sense. However, the current **AI technology** is **legit amazing**, and we're only a few years into this trend. While **LLMs (Large Language Models)** have plateaued, companies are working tirelessly to replace human workers with **AI agents**. This shift will likely continue, with **robots** and **humanoid robots** emerging as key drivers of the **AI hype** in 2026.

**Job Market: Will AI Replace Human Engineers?**

The **job market** is undergoing a significant transformation, with **AI coding tools** changing the landscape. While **software development** jobs are still in demand, the **Bureau of Labor Statistics** forecasts a 15% growth in **software development** jobs through 2034. However, the rise of **AI coding tools** has created a new class of jobs: **code janitors**, who will clean up the **garbage code** generated by these tools.

**Quantum Computing: The Next Big Thing**

**Quantum computing** is on the cusp of a breakthrough, with **Google's Willow chip** and **quantum echoes algorithm** making significant advancements. When **quantum computing** hits version 1.0, it will surpass the **AI bubble** in terms of impact. Researchers are racing to develop practical applications, and this technology has the potential to revolutionize industries.

**Wearable AI and Virtual Worlds**

**Wearable AI** is another trend to watch, with companies like **OpenAI** and **Nike** developing innovative products. **Virtual reality** and **augmented reality** are also advancing, with **Meta** making significant investments. However, these technologies will likely remain niche areas, with **chip designers** like **Nvidia** and **ARM** reaping most of the profits.

**Chip Designers and Fabricators: The Real Winners**

The **AI mania** has created an insatiable demand for **linear algebra**, and **chip designers** and **fabricators** are benefiting from this trend. Companies like **Nvidia** and **Taiwan Semiconductor** will continue to dominate the market, while **Intel** is poised for a turnaround after a significant investment from the US government.

**Cloud Providers and Nuclear Power: An Unlikely Combination**

The demand for **AI** is driving a surge in **cloud computing**, which is leading to a shortage of **electricity**. This has created an opportunity for **nuclear power** to make a comeback, with companies like **Ollo** developing **small modular reactors**. This trend could lead to a more efficient and reliable energy source for **data centers**.

**JavaScript and Front-End Development: The Latest Advancements**

On the **front-end** side, **ReactJS** still dominates, despite its limitations. New **JavaScript** frameworks like **bunjs** and **Ripple** are emerging, offering faster and more efficient solutions. **Node.js** is also improving, with support for **TypeScript** files and **TypeScripping**. As the **tech landscape** continues to evolve, it's essential to stay up-to-date with the latest **JavaScript** advancements.

**Conclusion: The Future of Tech is Unpredictable**

As we navigate the **unhinged world of tech** in 2026, it's clear that the industry is undergoing a significant transformation. From **AI** and **quantum computing** to **wearable AI** and **JavaScript** advancements, the possibilities are endless. While some trends may seem **overengineered** or **still in beta**, they have the potential to revolutionize industries and create new opportunities. Stay tuned for the latest developments in the **tech world**, and get ready to adapt to the ever-changing landscape.

**Social Media Post Ideas:**

* ""The **AI bubble** is still alive and kicking, but will it burst in 2026? #AI #TechTrends""
* ""Get ready for **quantum computing** to revolutionize industries in 2026! #QuantumComputing #FutureOfTech""
* ""What's the latest in **JavaScript** advancements? Stay up-to-date with the latest frameworks and trends! #JavaScript #FrontEndDevelopment""
* ""The **tech landscape** is changing fast! Stay ahead of the curve with the latest news and trends. #TechNews #Innovation""",2026-01-15T10:41:23.429987
freeCodeCamp.org,How to remove a list item by its value in Python,9KnVcWXUL8w,"Let's talk about the remove method in Python. This method finds the first occurrence of the item in a list and removes it. If the item is not found, then it raises a value error. Let's say you have this my list with the strings green, blue, green. If you call my list remove, pass in the string green as the argument, the list becomes blue, green. And you should also be aware that this method modifies the list in place.","**Mastering List Manipulation in Python**: Unlock the Power of the **Remove Method**

Are you looking to enhance your Python skills and efficiently manage lists? Look no further! In this insightful video, we delve into the world of list manipulation, focusing on the **remove method**. This powerful tool enables you to delete a list item by its **value**, making it an essential technique to have in your programming arsenal.

Here are the key takeaways from the video:

* The **remove method** finds the **first occurrence** of a specified item in a list and removes it.
* If the item is not found in the list, the **remove method** raises a **ValueError**.
* When using the **remove method**, keep in mind that it **modifies the list in place**, meaning it changes the original list without creating a new one.

Let's consider an example to illustrate this concept. Suppose you have a list containing the strings **""green""**, **""blue""**, and **""green""**. If you call the **remove method** with the argument **""green""**, the resulting list will be **[""blue"", ""green""]**, demonstrating how the **remove method** deletes only the **first occurrence** of the specified item.

To recap, the **remove method** is a valuable tool for list manipulation in Python, allowing you to remove items by their **value**. By understanding how to use this method effectively, you'll be able to write more efficient and effective code.

**Key Concepts:**

* **Remove Method**
* **List Manipulation**
* **ValueError**
* **First Occurrence**
* **Modify in Place**

**Social Media Post Ideas:**

* ""Boost your Python skills with the **remove method**! Learn how to delete list items by their **value** and take your coding to the next level. #Python #ListManipulation #RemoveMethod""
* ""Did you know that the **remove method** can raise a **ValueError** if the item is not found? Stay ahead of the game with our expert tips and tricks! #Python #Coding #ErrorHandling""",2026-01-15T10:43:35.047534
Google Cloud Tech,How to get started with Google Cloud Client Libraries,5ivFW9gYmq0,"Cloud client libraries. In the last episode, I talked about what they are and why they're so useful. I told you about how they significantly reduce the code that you need to write and handle all those low-level details like authentication. Now, [music] let's get a little bit more hands-on. We're going to set up an environment, get application default credentials configured, [music] and make our very first cloud client library call. This is what's what with cloud client libraries. If you're developing with Google Cloud on your local machine, you'll need to install the Google Cloud CLI or G-Cloud before you can access Google Cloud services. The Google Cloud CLI is part of the Google Cloud SDK. Not only does it let you manage Google Cloud resources from your terminal, it also handles authentication for your locally running application code. The instructions for installing the Google Cloud CLI vary by operating system, so I've linked instructions in the description. For the demonstration I'm about to walk through, I already have the CLI installed, just not configured. So, I've got a cloud storage bucket and I want to return a list of all the files that I have stored in it. Here's how I can do that with Python. Now, before I can run this, I'll install the dependencies with pip install. Rather than a single massive library, Google Cloud client libraries are split by service. Since I'm accessing Google Cloud Storage, I'll install the corresponding client library, Google Cloud Storage. You'll see this pattern for most of the services. Google Cloud compute, Google Cloud Secret Manager, and so on. This approach means you'll only install the code that you need, keeping your application light and clean. Let me do a quick rundown of the code here. First, I import the library for Google Cloud Storage. Next, I instantiate the client. The client is the main entry point for any subsequent calls to the API that I make in my application code. After that, I construct a request which in this case only requires the name of my GCS bucket as a resource path. And now the magic happens. The request is sent to Google Cloud using the list objects method of my client. And since the results are returned as an iterable object, I have a loop to simply print out the name of each object in my bucket. I'm going to run this now just to show you what happens. Like I mentioned before, I installed the Google Cloud CLI, but I haven't configured it. So, as expected, I get an authentication error. Our application doesn't know anything about who I am and what it's allowed to do on Google Cloud. To fix this, I need to get application default credentials or ADC for short. Application default credentials are a standard automatic way for your application to find the right permissions to talk to Google Cloud APIs. There are a few ways to provide your application with these credentials, but for local development, I'll show you the most straightforward approach. Run g-cloud o application-default login. This command opens a browser for you to sign in with your Google account and then creates a local credential file in a well-known location on your file system. You might receive a message like this one warning you about a missing quota project. Well, the quota project is a Google Cloud project that is responsible for billing and usage limits of an API call. I'll talk more about quota projects in a later video. This particular example doesn't need one. So, I'm going to keep going and run the code. Notice again that when we create the client, we don't explicitly provide any credentials. This is the magic of application default credentials. My code will automatically find the credentials I just set up and use them to authenticate to Google Cloud. And there we go. Now that I'm authenticated with my application default credentials, the code runs and I've got a list of my files right here. I didn't have to change a single line of my Python code to indicate credentials or other authentication details. With a single G-Cloud command, I configured my local environment and the client library automatically picked it up. That's the power of this approach. Now this is a very brief overview of how to get started with cloud client libraries with a very simple example as a preferred way of providing authentication to cloud client libraries. Application default credentials are an important [music] concept to understand. There's more to talk about there. So catch the next episode while I'll cover where your application is looking for those credentials, what they look like, and more. And as always, if you have any questions, feel free to drop them in the comments. Thanks for [music] watching. See you next time. Heat. Heat.","**Getting Started with Google Cloud Client Libraries: A Step-by-Step Guide**

In this episode, we dive into the world of **Google Cloud Client Libraries**, exploring how to set up an environment, configure **application default credentials**, and make our first cloud client library call. Whether you're a developer or just starting out with **Google Cloud**, this guide is perfect for you.

**Why Google Cloud Client Libraries?**

Google Cloud Client Libraries simplify the development process by reducing the amount of code you need to write and handling low-level details like **authentication**. They're split by service, allowing you to install only the code you need, keeping your application light and clean.

**Setting Up Your Environment**

To get started, you'll need to install the **Google Cloud CLI (G-Cloud)**, part of the **Google Cloud SDK**. This allows you to manage Google Cloud resources from your terminal and handles authentication for your locally running application code. Follow the instructions for your operating system to install the CLI.

**Configuring Application Default Credentials**

**Application Default Credentials (ADC)** are a standard way for your application to find the right permissions to talk to **Google Cloud APIs**. To configure ADC, run the command `g-cloud auth application-default login`, which opens a browser for you to sign in with your Google account and creates a local credential file.

**Making Your First Cloud Client Library Call**

Using **Python**, we'll install the **Google Cloud Storage** client library and write a simple script to list the files in a **Google Cloud Storage** bucket. We'll import the library, instantiate the client, construct a request, and send it to Google Cloud using the **list objects method**.

**The Power of Application Default Credentials**

With ADC configured, our code automatically finds the credentials and uses them to authenticate to Google Cloud. We don't need to explicitly provide credentials, making the process seamless and efficient.

**Key Takeaways**

* Install the **Google Cloud CLI** to manage Google Cloud resources and handle authentication
* Configure **Application Default Credentials** to simplify authentication
* Use **Google Cloud Client Libraries** to reduce code and handle low-level details
* Install only the necessary client libraries for your services, keeping your application light and clean

**What's Next?**

Stay tuned for the next episode, where we'll dive deeper into **Application Default Credentials**, exploring where your application looks for credentials, what they look like, and more. If you have any questions, feel free to drop them in the comments.

**Social Media Post Ideas**

* ""Get started with **Google Cloud Client Libraries** and simplify your development process! #GoogleCloud #CloudComputing""
* ""Did you know that **Application Default Credentials** can simplify authentication? Learn more about ADC and how to configure it! #GoogleCloud #Authentication""
* ""Reduce code and handle low-level details with **Google Cloud Client Libraries**. Perfect for developers and beginners alike! #GoogleCloud #CloudDevelopment""",2026-01-15T10:53:17.258561
Andy Stapleton,This AI Tool Could Replace Half Your PhD Work (Heres How to Use It Safely),A-epnbwxMlA,"answer. This has become an awesome AI tool for academia and research, but there's so much that they're offering that it can get a little bit confusing. So, today we're going to go over the workflows that I think make academia and research much easier. And as you can see, it's not exactly easy, but that's what this video is all about. All right, then. Here we go. I've reviewed Answer This on this channel before, and you told me it was far too expensive. So for you, I've spoken to the CEO and the co-founder and I have said, ""Give me a deal."" So down below is a uh deal which offers you 25% off the monthly fee, which is the highest discount they've ever given. So hopefully then you will feel more confident that it's aligned with the pricing of other AI tools. So let's get into it. So this is what it is. A question to final publication all-in-one research assistant. This tool has been trying to replace every single workflow that you need as an academic to get from idea, find the literature to publication. Have they achieved it? Well, I think they're getting closer, but it's not quite there yet in terms of this full offering. But there are some awesome tools that you should know about. So, the first thing you need to do when you're approaching a tool like this is work out what you actually need to do. And there are two broad things that I think this tool offers and we'll talk about that now. So the first thing is a simple inquiry. If you have a question, you can use their quick uh question and answer service which uh gives you a research paper filter to come up with a simple answer. So that's really good if you're just sort of like you know in a normal research environment something pops into your mind like oh I wonder what the literature says about that. They offer that and it is great. But they've then also got this other offering which is the full review. And as you can see down here, it gets really convoluted in all of the things you can do. But we'll be going through the workflows that allow you to understand exactly what to do, where to go, what button to push because they offer so much that it can get a little bit confusing. So here is a mud map and we'll go through one at a time. But first of all, let's have a look at this the inquiry. So the first thing you need to do is come up with a question and that's pretty easy. throughout your research life, all these questions are popping into your mind and you can go here and use their quick Q and answer function and their research paper filter to end up with this response. Normally there's a text response and then a table response and this is what they are now calling their canvas. So let's go and have a look at that. So this is the quick Q&A and in the simple response you can ask papers, you can ask the internet, you can ask your library if you have one, if you've uploaded papers into this. Um and also you can attach files. But this filter is really where the power lies because here you can see you can look at number of citations that you want the journal quality the publication types and also a load of other things um including publication date their start date end date and that's really good for getting recent papers but if you put that in so I did this with a really simple question how do exfoliants enhance skin texture now when you first get it it looks like this it's columns one side and then the other side But I actually don't like that review. I like this one where you can see it's just like here's the information that you need and it's completely referenced. If you click on this, it takes you down to the reference and then as you scroll down, you get the table. So, it's much more aligned with other research tools that I've seen. Um, and I like the fact that, you know, it gives you the information and then if you want, you can go down and actually explore and interrogate the references a little bit better. So overall, this is sort of like the very simple way that you can use answer this, but it gets so much more powerful and they tease it down here and you can do all of these things, but we'll save this for I think which is the better version of this search, which is the full literature search and then this becomes really powerful and I think we'll save that. So that's the first one. That's this one, which is the inquiry or let's put that full screen so I'm professional. This is the question. You ask a quick question, you get your research fill or paper. Great. And the next thing is this this mud map that we'll go through. So you can see how you can actually go from prompt to a load of different outcomes and ultimately a little bit of a document that you can use for to first draft a literature review or something like a peer-reviewed paper introduction. Let's give it a go. Okay. Then besides this quick Q&A, when you first sort of like log in, it is default this full review. And this is where I think the majority of people will probably go when they're first using this. And it is so powerful, but you have to know what you want going into it because it can get confusing about exactly what the outputs um allow you to do. So down here, you can ask any research question and you got the same filters as before. But when you go to filter this time, you can see you've got a little bit more. This is the literature review settings, the number of main sections you want, the sub points per section, the topics to cover if you've got something you want to sort of like specifically discuss in this literature review. And then you've got here minimum citations. I actually like whacking that up to like 20 because if I'm doing a literature review, I want it to try its hardest. And then you've got journal journal quality. I often put that just at Q2. And then you've got all of the normal stuff that we had before. Once you go uh and click that it goes away and it does it sort of like stuff and then after about I don't know uh five minutes it produced something like this and you can see it is in depth. Once again I've gone into this single column layout and it is big. It's got tables. It's got references. You can see that it's found so many things. If we keep keep scrolling, you can see this is actually a pretty detailed first draft of a literature review and it sort of uh makes complete sense of the headings they've chosen and that sort of stuff. And this is the citation it's chosen. So 14. Okay, I don't mind 14, but you can see down here that uh yeah, here are all of the citations that it's found. It's page one of 75. So there's uh 372 papers that it's found. But in the literature review, it's just included 14. So don't be put off by the 14 number. It's actually found all of this stuff. And now this is where the true power of ads to this lies because on this what they're calling the canvas, you can do a range of different things. So let's go over here and have a look to see how this breaks down. So this is where we're up to at the moment. We've put in a prompt. We've asked for a full review. We've got the these literature review settings. And then we end up with this canvas. The first thing you can do, and probably the most obvious one, is you can ask follow-up questions. So, all you have to do is go over to the follow-up questions, and you can see here, ask follow-up questions. So, you could ask for uh what are the research gaps? And it on this canvas, it will allow you underneath that to then get an answer to this question. What are the research gaps? And it will go or find resources and give you that stuff. So that's a pretty simple way of finding out uh you know a little bit more detail about the things that you want to find out about given your search. Now this is where a new feature comes in which is this notebook. So notebook essentially allows you to create a document and edit a document. One of the most annoying things about all of these is that you know you end up with all of this text and you're like what do I do with all of this text? Well, if it's useful to you, you click up here to notebook and then you got open default notebook or add to default notebook. I'll click here and then we get access to um the notebook panel. And this notebook panel is kind of like Google Docs where you can uh you know format it, you can highlight it and you can do all of these things. You can reformat and you can export. So there's a lot of things you can do in here and also as you go along you can add to this notebook. Um it is uh you know fully customizable I mean editable and you can um yeah export this into wherever you like and it does save it in my library which is over here. It does save it as a notebook. So you can see here are all of the notebooks that I've generated. We've also got papers canvas. So each canvas is each question essentially where you start but the notebook is where all of the writing happens. That's what I want you to know about that. So, we'll go back uh to our uh canvas. So, we go to go library to canvas. And then where were we? There. This was it. And you can see that this is where we ended up. But this is a canvas. We've asked a follow-up question. And uh now we can choose to do a range of different things. Let's head over to our mud map and it'll hopefully make more sense to you because once we've done the notebook thing and we've generated a notebook and maybe saved some notes, there are a number of things we can do and that's this panel. So this panel is where a load of things can happen. You can chat with the papers that you've just found in the table. You can create a new table which is just a new table of the literature you found and we'll talk about how to use that. You've also got biblometric analysis, citation map, new search new papers and agents. Well, not quite yet. We'll see about that in a minute. But ultimately, these are all of the things you can do on this initial canvas. And it doesn't sort of like navigate away. It just gets added underneath the results. So, first thing first, let's have a look. We want to chat with papers. Great. So, we need to select some papers and then we can start a conversation and we get this. So, let's head over and do that. Now when we go down here you can see if I select a couple of these papers all we have to do then is click on this tab at the bottom bon and you get chat with papers. I've selected two papers. If we want more um let's say we want to filter it. So I want to filter I want uh start date let's say only from 2020. So let's have a look. We'll go to 2020. Come on. Click January 2020. Okay, good. Apply. And then we'll get all of the papers that are from 2020. All. And how many of that? 11 selected. Great. And then we'll go to down here, chat with papers. And then another interface will pop up. So if you're in the early stages of a research career or a project and you just want to find out what's going on in the world of your research field, then this is what it is. Okay. remove papers without PDF, but you can put in a lib key which gives you access to the full papers through your library. But now it will put in all of the papers and we can start a conversation and ask stuff. What are the main findings? Summarize uh what are the limitations of this research. So you can see that there's a load of things that it's put into this and we can ask any question a really nice backwards and forwards if you want to chat with papers and this workflow is really great if you are in that exploratory early phase then we can also do something else from this canvas we've generated we can create a new table. So this table looks like this and it's very similar to the table that's been sort of spat out as part of the initial search. But we can use that uh table to investigate something a little bit more uh you know related to let's have a look. How do I go back to that? Okay, because it's canvas it spills out at the bottom. So if you want to go back to your initial table, you got to scroll up to the top to where that is which is here. And you can see that I've got that 11 selected. And now I can go create a new table which will only be these uh these references that I've selected. And the great thing about these tables is that there we are. Now we've got a new table at the bottom of the canvas that we've generated. And the great thing about this is each row is a paper and now we can add columns. So we want research gaps for each thing. And you can even put in your own um bon you can even put in your own uh uh prompt here to say what kind of data you want to extract from each individual paper. So something like we see in size space and consensus. Uh this can now be done here which is really great. So you can see research gaps, research gaps, research gaps, all of this stuff can be found out by adding a column and you can put in your own things. So here abstract um let's have a look. We want to get rid of that. We want to put in future work. Why not? So we want to know for each paper what their future work was. That is something that maybe we can use to springboard our own stuff. Whatever. Yeah, you can do that if you want. There we are. Easy peasy. So that is the create a new table function. That's great. a great way to filter through the stuff that your initial search found and to add columns uh to look for specific information. There we go. Now, we got biblometric analysis. This is something I've not seen in any other research tool to date. So, if you really want to get a grasp, a visual grasp that is of all of the stuff that's offered um up from this search, then you can go here and it will do a biblometric analysis. So, let's go have a quick look at that. So the biblometric analysis I've done before. Um it's in my canvas. Here it is. So I wanted to know uh you know publications from 2022. So it created only those two. But if you select much more let's have a look. Let's go all the way to the top where I wanted that information. We need to go to this view. Scroll down. You can see that it's got so many things that it can get confusing about exactly like what you're doing and how. So here I've got 11 selected. I want a biblometric analysis from those 11 papers. It will get added to the bottom of this canvas. And here we are. So you can see publications by year. You can see this has been a great year for this uh research field. We get the citations by year. So we'd expect, you know, 2022 was good. We expect them to be more early on. Obviously 2025 only six. Come on now. And then combined publications, citations, and then we got citation impact, word clouds, top terms, top authors. So if you really want to find out the uh lay of the land so to speak of a particular research field then doing something like this is really great really great early on or if you do well do want to kind of like inject a little bit more um energy is that right term into a research field that you've been working in you can go in and be like have I missed anything have I missed any keywords have I missed any authors have I missed any top terms that I should be looking at it's just a nice sense check I think and that is the biblome ometric analysis which you can add to this canvas. Then you've also got a number of other things. We'll skip over citation map because we'll talk about that in a minute. But we've also got search new papers. Now this is a little bit sneaky I think because search new papers really let's go full screen so you know that I'm a professional. Really is just this generated again. But instead of selecting papers, you now just select it with a prompt. And you'll see what I mean in a minute. All right then. Let's go back over here. Let's go back up to our papers. Oh, no. We don't need to do that anymore because we can go to search new papers. This pops up. And then you can ask for something else. It's not doesn't even need to be related to what you've just done on that canvas. Um, so here we are. What are the latest treatments for Alzheimer's disease? Let's search that. It will search from papers and then it'll add it to the bottom of the canvas. So, if you are wanting to do something a little bit outside of the uh first response, you can then get that. And you can see it's put it down the bottom here. You can do everything that you can do with tables in this new prompt. Easy peasy lemon squeezy. There we are. That's where we're at with that. And then also, we've got agents. Uh have we? No. Coming soon. That's a bit cheeky, isn't it? So, they've put uh agents here. And if you click on it, it just says coming soon. So, we will be keeping an eye out for that. And one thing I do want to say is that remember this little chap all the way up here from ages ago in the video? Well, you can actually sort of send stuff to the notebook to be included. So, if you find out something here, if you find something here, if you find something here, you can send it to a notebook and then you can include it in the thing you are writing in the output. So, there are all of the things you can do with answer this. It is complicated. It is a little bit convoluted but knowing these outcomes I think will help you understand exactly what you Yeah, I'll go full screen again so I look professional. Um you knowing what you can do from one single prompt and you can kind of like you know uh what do you call dovetail it out into a range of different things I think is where the power lies. But it can be confusing about what exactly you can do and when and where and with what. So this is what you can do. If you head back over to answer this, you can see that there's a ton of other things you can do as well. You can create a citation map. So, from a simple paper, you can create a citation map. Let's say uh let's go back over here and have a look at this one. And then we set this as origin. And you get to um interact with the graph once it's finally uploaded. But there we are. There's all of the papers that it found that are interacting with the origin paper that I've put in. You can also change here um from this output. You can look for the most cited papers. It only changes this table down here. You can look for the most connected papers and you can also look for the top contributing authors. Lovely jobly. You've also got diagrams. Diagrams. You can create mind maps, user journeys. We won't go into this right now because I'm waiting for this the graphs to happen. And I think that's where the most power will be with this. But you can see that you've got all sorts of different graphs that you can put in from a single prompt. And you've got agents. You've got Naturalizer, Essay Writer, Gapfinder, AI, Paraphraser, a load of different things. Go check out my other video on Answer This where I go through this uh agent section in a lot more detail. But that is all of the stuff you need to know about answer this at the moment. It's powerful. Um, let me know what you think. If you like this video about AI workflows, go check out this one where I talk about writing a peer-reviewed paper using awesome AI tools. I think you'll love it.","**Unlocking the Power of AI in Academia: A Comprehensive Guide to Answer This**

The world of academia and research is on the cusp of a revolution, thanks to the emergence of **AI-powered tools** like Answer This. This innovative platform is designed to simplify the research process, making it easier for academics and researchers to find, analyze, and publish their work. In this summary, we'll delve into the features and capabilities of Answer This, highlighting its potential to **replace up to half of the work** involved in PhD research.

**Getting Started with Answer This**

Answer This is an **all-in-one research assistant** that helps users navigate the entire research process, from idea generation to publication. The platform offers two primary modes of operation: **simple inquiry** and **full review**. The simple inquiry mode allows users to ask quick questions and receive concise answers, while the full review mode provides a more comprehensive analysis of the literature.

**Key Features of Answer This**

1. **Quick Q&A**: Ask simple questions and receive answers based on a **research paper filter**, which can be customized to include specific journals, publication dates, and citation counts.
2. **Full Review**: Conduct in-depth literature reviews, complete with **citation maps**, **bibliometric analysis**, and **notebook** functionality for organizing and editing content.
3. **Canvas**: A customizable workspace where users can ask follow-up questions, create new tables, and analyze data.
4. **Notebook**: A document editing tool that allows users to format, highlight, and export their work.
5. **Bibliometric Analysis**: A visual representation of the research landscape, including **publications by year**, **citations by year**, and **top authors**.
6. **Citation Map**: A graphical representation of the relationships between papers, allowing users to identify key authors and publications.
7. **Diagrams**: Create mind maps, user journeys, and other visualizations to help organize and present research findings.

**Workflows and Use Cases**

Answer This is designed to accommodate various research workflows and use cases, including:

1. **Exploratory research**: Use the platform to identify research gaps, explore new topics, and discover relevant literature.
2. **Literature reviews**: Conduct comprehensive reviews of the literature, complete with citation maps and bibliometric analysis.
3. **Paper writing**: Use the notebook and canvas features to organize and edit research papers, including peer-reviewed articles and thesis chapters.

**Conclusion**

Answer This is a powerful **AI tool** that has the potential to revolutionize the way academics and researchers work. By providing a comprehensive and customizable platform for research, Answer This can help users **save time**, **increase productivity**, and **improve the quality** of their research. Whether you're a seasoned researcher or just starting out, Answer This is definitely worth exploring. With its **25% discount** offer, now is the perfect time to try out this innovative platform and discover the power of AI in academia.",2026-01-15T10:55:29.530030
The AI Advantage,Claude Cowork is Here! Full Breakdown + Testing,BWAr7gTkll8,"Okay, we have to talk. It's not often that something is released in the AI space that I consider a serious breakthrough, but this is one of those moments. Andropic, the maker of Claude, which you might know as one of the main competitors to Chad GPT and Gemini, released a new thing. They call it Claude Co-work, and it's probably the closest thing to a consumer AGI like product that I have seen yet. Now, it's just a research preview. It's the very first look. They built this thing in 10 days. But I think a lot of people come into AI with this idea of AI actually doing everything for them and then they realize that the reality right now is that it's more of a assistant to you. This product changes that. It's called co-work. The availability is very limited. You need to be on a max plan and it's only available on the Mac desktop app. Again, it's a research preview for now, but I really want to talk to you about it and show you some first demos of it actually working on my machine here. And if you're wondering what this is about, well, let me give it to you in two ways. First of all, in the simplest term possible, this is a agentic AI system that is actually built to do things for you, to move files around, to connect to some other services with as little involvement from you as possible. That's the idea. It is a different version of another app that you might already be familiar with, Claude Code. That was their application for developers that was already doing this, writing code, creating files, pushing it to GitHub repositories, hosting it on the web, all by itself. And way more than that, too. And clot code was one of the big hits in the entire AI space over the past what is it I think 10 months since it released. And the interesting thing about claude code as it got better over time was that people were bastardizing the developer tool to do other tasks. They were using it to develop marketing plans. They were using it to develop product ideas. They connected it to image and video APIs and created whole Instagram campaigns with it and stuff like that. And as that kept happening, some startups took notice of that and they built a standalone product. You might be familiar with products like Manos and GenSpark that we also covered on this channel recently. They're just these agentic products that try to build this universal agentic tool but for non-developers. Well, and that's where we arrive at Claude Co-work. This new research preview from Enthropic. They now built their own version of a agentic AI system for non-developers. And that's what we'll be looking at today. It's a system that can create and organize files. It can send messages. It can connect to other applications. Uh spoiler alert, it's really not that good at it, just like all other connectors before. But the point is, this is the AI assistant that most people when they hear about AI are secretly hoping for. They want it to organize their life, make them more money, make them happier, free up their time, all that. But what they find is a chat interface where they actually have to take action. Still super useful, but we know there's more. And this is the first product from one of the big players that attempts to do that. So, let's dive right in and let me show you what it can do in principle. This is a first look at a research preview. As I mentioned, this is only available on the Mac app on the Max plan, which is $100 per month. And very basically, you see the same chat interface that you might be familiar with from other apps, but this goes way deeper because it has access to your drive. It has access to your connectors. If I just briefly check the settings here, you'll see if I go into connectors, I could connect all of these external services. Now, the problem here is these haven't worked super reliably before, and that doesn't change. Nothing about these connectors changed right now. What has worked here before is here this file system plugin where it just deals with your local files. Brave search, which is just an alternative search engine to Google, that works decently well. And then I've said this before on the channel, but Claude and Chrome, the little extension that if you go into Google Chrome that can like remote control your browser, those three things worked really well. And all of those are accessible within Claude Co-work. Okay, so with that being said, we're basically ready to give this a first try by doing one of the demo examples they showed in their blog, saying something like, ""Help me organize all of the files on my desktop."" So, as I type in this prompt, I have to do one critical thing, which is actually choose a working folder. So, I'll just select the desktop. I'll tell it to always allow access to my desktop here. And now it can work there. Let's just say let's go and see how this performs live. Now, if you look here over at my desktop, you will see that it is pretty clean, but that's because I use this sneaky sneaky technique where every time there's a lot of files, I just create a new folder called before and then the current date and then I dump everything else in there. So, within these folders, there's hundreds if not thousands of files that are just not visible, but they're still on my desktop and it's still a mess. Let's see if clot co-work can help. Okay, so you'll see a lot of similarities here to clot code if you're familiar with that already. It starts by creating a plan and asking you follow-up questions here. In this case, it asks me, ""How would you like me to organize your desktop files?"" Well, I want them by project topic. Screenshots I don't want to delete. I'll just move them to a screenshots folder. And then it asks if it should consolidate existing archive folders. Yeah, merge into one archive. Like this technique of me creating archive folder every few weeks is not great. Now instead of paying off the debt and where back in the day I was like yeah let's future ego deal with that. I don't have to plot co-work. Maybe it does pay off to be lazy after all in this aentic future. Well let's see how this goes. Maybe I'm wrong. Okay so it created a categorization system for various things that I worked on. Found wallpapers but also projects related to my book that is actually now available on Amazon. Quick shout out. Um find the link in the description. You can get it now. But this is a ultimate chat prompt book written by me. But just know this is the type of book that is really aimed at people who are getting into the space. So it's a perfect gift for a family member. If you're watching this channel and checking out the latest Gentic Developments, you're probably a bit further along. Anyway, link in the description and let's return to reviewing this. Okay, created a new folder structure. It removed it cleaned up several files and there it is. It actually did not prompt me a single time. Okay, let's review. So here is my desktop. Okay. Okay, this is cleaner than ever. I love that it kept this file um documents for demos that I created. I had like just a bunch of different example images and videos I used over time. Beyond that, I have a screenshots folder with all screenshots. Okay. Wallpapers, everything relating to the book and then a big archive folder. Okay. So, I see. So, this is where a lot of the mess is nested within. So, okay. So, I'll just tell it I want you to also organize the archive folder. And then maybe if I like what I see, we can merge that with the desktop organization. But initially, this worked really well. Just consolidating those archives and finding all the nested archives would have been tedious task. Okay, follow-up questions. And yeah, I want to merge relevant documents with existing desktop folders. And as this finishes up, I'll actually start a second task which this one will be using the Chrome extension so it can remote control my browser because I've just found this thing to work most reliably out of all the connectors they have there except the one that uses your file system too. So just try something simple and let's see. This is the first attempt of me doing this here and I'll just show you the result as is. So, let's see if it can do it. Open my Gmail account in the browser and tell me about the free most important emails from the past 24 hours. Okay, so in my Gmail account, I actually already opened up spam email that I have where I just subscribe to different services and newsletters and I don't really check it regularly. And I just wonder what it'll come up with here. So, let's just watch it work. All right, there it is. It opened up all the emails in our main YouTube inbox. And then it says, ""This Google Workspace security alert is important."" Okay, sounds about right. And then, a paid video collaboration and a customer having trouble with access. I'll make sure to let the team know about this. Other than that, I'm here to judge how well it pulled in the context, not how well it prioritized these things, as this doesn't have any context on what we actually care about. For example, we're phasing out the collaboration with external companies, so the sponsor email would not be relevant here. But it seemed to have worked as I expect. And it was really simple, even simpler than using the web browser add-on because usually when it works within here, you kind of have a separate window, a separate thing to manage in your head. Now it kind of got centralized into claude co-work which I really like cuz I could just do tasks from within here together with all the other AI related tasks but now I just know it has this extra layer of actually having access to my browser to my files. So that's really neat. Now to round out the video, let's return to the desktop organization and see what it did here. And as you can see it successfully worked in parallel with this other task and it merged all the files on the desktop. Here's a big overview. So now it has more folders. And if I open up the archive file, well, this looks way better than what we looked at just a minute ago. All the presentations, all the images, some bookmarks that I don't need. Yeah, this is actually useful. All my system prompts that I worked with on the desktop are right here. These installers I don't need. This is a great way to get a grasp of your desktop. Now I want to do one last thing because this really shows how everything that you've learned in AI so far combines with this new tool but it just reaches deeper into your world and your computer and that is by turning it into something different and that is by creating a web app that visualizes the new file structure through an artifact which is application or website and there it is. Okay, so this is the web app. Honestly, at first I thought, okay, what a useless example. You could have come up with something else. But now that I see this, not bad. Look, a tree map. Okay, deep archive. Not bad. And ultimately, the point is that it just brings everything together, but it gives its deeper reach in one app, in one interface. I don't have to have terminals open. I don't have to have multiple browser tabs open. It's just here in this app here under the co-work tab. And if I just want to use chat as I have been before, well, I just tab over and do that over here. If I'm developing an application, I could tab over here and use it in this code tab, but with claude code, I've still been using the command line interface, but now that it's all here, it just makes sense. Now, arguably, this is just a research preview, and as they stated themselves, they built this thing in 10 days, but I really do strongly believe that this is the direction the AI space is developing into. And just because the connectors are not that reliable yet doesn't mean it will stay that way in the future. Organizing your desktop makes sense. Me and the team need to do more research and more testing to find further use cases that will work and we'll follow up with that in Friday's news you can use video and future videos. So subscribe for that. But ultimately I know that this is a direction that all big companies will pursue and all smaller companies that will build features like this will eventually have to niche down to something else because this is too big of an idea for one of the big players not to build themselves. At this point, it's just a question of time when we'll see the chatbt version of this and future versions from Enthropic that are not research previews, which all things considered actually works kind of well already. All right, that's everything I have for today. My name is Eigor Pagani and I hope you have a wonderful day.","**Introducing Claude Co-work: A Revolutionary AI Assistant**

The AI space has just witnessed a **breakthrough** with the release of Claude Co-work, a **research preview** from Enthropic, the maker of Claude. This innovative tool is poised to change the way we interact with AI, making it a more **autonomous** and **agentic** system. Claude Co-work is designed to **assist** users in organizing their files, sending messages, and connecting to other applications, all with minimal human intervention.

**What is Claude Co-work?**

Claude Co-work is an **AI system** that builds upon the success of Claude Code, a developer tool that can write code, create files, and push them to GitHub repositories. However, Claude Co-work is designed for **non-developers**, making it more accessible to a broader audience. This **agentic AI system** can create and organize files, send messages, and connect to other applications, making it a powerful tool for anyone looking to streamline their workflow.

**Key Features and Benefits**

Some of the key features of Claude Co-work include:

* **File system plugin**: allows Claude Co-work to access and organize local files
* **Brave search**: an alternative search engine to Google that works decently well with Claude Co-work
* **Chrome extension**: enables Claude Co-work to remote control the browser
* **Connectors**: allows Claude Co-work to connect to external services, although these are still in the experimental phase

The benefits of using Claude Co-work include:

* **Increased productivity**: by automating tasks and organizing files
* **Improved workflow**: by providing a centralized interface for managing multiple tasks
* **Enhanced user experience**: by making it easier to interact with AI and access various applications

**Testing and Demo**

The video demonstrates the capabilities of Claude Co-work, showcasing its ability to:

* **Organize desktop files**: by creating a categorization system and merging existing archive folders
* **Connect to Gmail**: and retrieve important emails from the past 24 hours
* **Create a web app**: that visualizes the new file structure through a tree map

**Future Directions and Implications**

While Claude Co-work is still a **research preview**, it marks a significant step towards creating more **autonomous** and **agentic** AI systems. As the technology advances, we can expect to see more **reliable connectors** and **improved performance**. The implications of this technology are far-reaching, with potential applications in various industries, including:

* **Productivity and workflow management**
* **Customer service and support**
* **Marketing and sales automation**

**Conclusion**

Claude Co-work is a **game-changer** in the AI space, offering a glimpse into the future of **agentic AI systems**. While it's still in the experimental phase, it has the potential to revolutionize the way we interact with AI and streamline our workflow. As the technology continues to evolve, we can expect to see more **innovative applications** and **improved performance**. Stay tuned for future updates and developments in this exciting field! 

**Social Media Post Ideas:**

* ""Get ready to revolutionize your workflow with Claude Co-work! This game-changing AI assistant can organize your files, send messages, and connect to other applications with minimal human intervention. #AI #Productivity #Innovation""
* ""What if you could have a personal AI assistant that can help you with tasks and projects? Introducing Claude Co-work, the future of agentic AI systems! #AI #Assistant #FutureOfWork""
* ""Take a sneak peek at the future of AI with Claude Co-work! This research preview is just the beginning of a new era in autonomous and agentic AI systems. #AI #Future #Innovation""",2026-01-15T10:58:35.841041
The AI Advantage,Setting Up AI to Grow a Plant ,rmf8rKB751A,"People have been abusing clot code for all sort of activities. Some of them just use it as their daily driver instead of chat GPT. Some people use it to generate images and entire marketing campaigns. And yet again, others get super creative with it and do things like this where they hook it up to various tools. They give it the ability to turn on lights, turn on a heat mat, regulate the humidity, and add water. And then they let claw code that is built for development grow a plant. And this is just one of many examples of really people using this for something that it's not intended for, but it's a solid agentic framework and they're sort of exploring this way.","**Unlocking the Potential of AI**: Discover How **Clot Code** is Being Repurposed to Grow a Plant

In a fascinating display of creativity and innovation, individuals are pushing the boundaries of **Artificial Intelligence (AI)** by utilizing **Clot Code** in unconventional ways. Initially designed for development purposes, **Clot Code** is being leveraged to control various tools and devices, such as **lights**, **heat mats**, **humidity regulators**, and **watering systems**. By integrating these components, users are effectively creating a **smart gardening system** that enables **AI** to nurture and grow a plant.

The key takeaway from this experiment is that **AI** can be repurposed to achieve remarkable results when combined with **creative problem-solving** and **outside-the-box thinking**. By exploiting the **agentic framework** of **Clot Code**, individuals are exploring new possibilities and applications for **AI** that extend far beyond its original intent.

This innovative approach highlights the **versatility** and **potential** of **AI** in various fields, including **automated gardening** and **environmental control**. As users continue to experiment and push the limits of **AI**, we can expect to see more groundbreaking applications and use cases emerge.

**Important Keywords and Concepts:**

* **Clot Code**
* **Artificial Intelligence (AI)**
* **Agentic Framework**
* **Smart Gardening System**
* **Creative Problem-Solving**
* **Automated Gardening**
* **Environmental Control**

**Social Media Post Ideas:**

* ""Did you know that **AI** can be used to grow a plant? Discover how **Clot Code** is being repurposed to create a **smart gardening system**! #AI #Innovation #Gardening""
* ""Unlock the potential of **AI** and explore new possibilities! Learn how **Clot Code** is being used to control **lights**, **heat mats**, and **watering systems**. #AI #Technology #Automation""
* ""Get ready to be amazed by the **versatility** of **AI**! From **automated gardening** to **environmental control**, the possibilities are endless. #AI #Innovation #FutureTech""",2026-01-15T10:58:41.950436
DeepLearningAI,New course! Document AI: From OCR to Agentic Doc Extraction,ltxsE1rhSfI,"I'm thrilled to introduce Docman AI from OCR to agentic doc extraction both of landing AI where I'm executive chairman and taught by David Park and Andrea Drop. A lot of data is locked up in PDF files and other documents on our laptops on the web and in company's cloud storage. This course shows how to transform complex documents into OM ready markdown text. You learn how to detect document structure and extract information from both text and visual elements such as charts and checkboxes and tables. It turns out this opens up opportunities to build a lot of new applications to process financial documents and medical records to review academic research papers which is something I recently worked on myself and a lot more. Traditional optical character recognition or OCR extracts text but loses the structure or the layout information of a document. Take for example a research paper. On one page you can have two column text and an abstract and footnotes and tables and charts with captions. OCR might be able to extract out the text from these components but it typically misses the context and the order in which these elements appear. Additionally, it does not capture the structure of complex tables. They can have merge cells or empty cells and might miss charts entirely. To actually extract this information and a gentic workflow works much better. It can first identify the different pieces of the document and then extract information piece by piece. In this course, you start by implementing this pipeline from scratch, combining layout detection and elebased reasoning to process documents. Then you learn to use agentic document extraction or AD a tool designed by lenai to automate this entire workflow for you. Thanks Andrew. Ad treats individual pages of documents as images where meaning is encoded in layout structure and spatial relationships. Traditional OCR and LLM based approaches flatten tables and figures into plain text losing much of that structure context and visual semantics. In contrast, AD uses custom visual models that interpret complex tables, graphs, images, charts, and other elements as visual objects, grounding every extracted field to a precise location on the page and using the positioning of the different objects to interpret the meaning. On top of this, AD's agentic orchestration layer iteratively breaks down complex extraction tasks, reasons over the document, and validates results through multi-step spatialware reasoning and workflows. You'll learn how to integrate ADE extracted information into rag pipelines. Finally, you'll implement a cloud-based version on AWS using an event-driven architecture that automatically triggers AD for document processing whenever new documents appear. And this creates an enterprisegrade pipeline where your [music] RAG system always has access to the latest knowledge in your document collection. >> Today, a lot of data has been collected, but it's still locked up in documents. This course shows you how to extract information for analysis or processing by AI. [music] I'm seeing this open up a lot of opportunities to create new applications. So, I hope you build some cool things with what you learn here.","**Unlocking Hidden Data: Introducing the Document AI Course**

Are you tired of having valuable data locked up in **PDF files** and other documents? Look no further! The new course, **Document AI: From OCR to Agentic Doc Extraction**, is here to revolutionize the way you extract information from complex documents. Taught by **David Park** and **Andrea Drop**, this course will show you how to transform **unstructured data** into **machine-readable text**, opening up a world of possibilities for **data analysis** and **AI processing**.

**The Limitations of Traditional OCR**

Traditional **Optical Character Recognition (OCR)** extracts text from documents but loses the **layout information** and **context**, making it difficult to understand the relationships between different elements. For example, a **research paper** with multiple columns, tables, and charts can be challenging to extract information from using traditional OCR. This is where **Agentic Document Extraction (AD)** comes in  a game-changing technology that can identify and extract information from complex documents with precision.

**How Agentic Document Extraction Works**

**AD** treats individual pages of documents as **images**, where meaning is encoded in **layout structure** and **spatial relationships**. This approach allows **AD** to interpret complex tables, graphs, images, charts, and other elements as **visual objects**, grounding every extracted field to a precise location on the page. The **agentic orchestration layer** iteratively breaks down complex extraction tasks, reasons over the document, and validates results through **multi-step spatialware reasoning** and **workflows**.

**Course Highlights and Key Takeaways**

In this comprehensive course, you will learn how to:

1. **Implement a pipeline** from scratch, combining **layout detection** and **element-based reasoning** to process documents.
2. **Use Agentic Document Extraction (AD)** to automate the entire workflow.
3. **Integrate AD-extracted information** into **RAG pipelines**.
4. **Implement a cloud-based version** on **AWS** using an **event-driven architecture**.

**Unlocking New Opportunities**

By mastering **Document AI**, you'll be able to create new applications that can process **financial documents**, **medical records**, and **academic research papers**. The possibilities are endless, and this course will give you the skills and knowledge to unlock them.

**Join the Course and Start Building**

Don't miss out on this opportunity to revolutionize the way you work with documents. Join the **Document AI: From OCR to Agentic Doc Extraction** course today and start building innovative applications that can extract valuable insights from complex documents.

**Social Media Post Ideas:**

* ""Unlock the power of #DocumentAI and start extracting valuable insights from complex documents! Join our new course and learn how to transform unstructured data into machine-readable text. #AI #DataAnalysis""
* ""Did you know that traditional #OCR has limitations? Discover how #AgenticDocumentExtraction can help you extract information with precision and accuracy. #DocumentAI #DataScience""
* ""Take your #DataAnalysis skills to the next level with our new course on #DocumentAI! Learn how to implement a pipeline from scratch and integrate AD-extracted information into RAG pipelines. #AI #MachineLearning""",2026-01-15T11:01:59.242799
